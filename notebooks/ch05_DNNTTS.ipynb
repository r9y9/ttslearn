{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eleven-height",
   "metadata": {},
   "source": [
    "# 第5章 深層学習に基づく統計的パラメトリック音声合成\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/github/r9y9/blob/master/notebooks/ch05_DNNTTS.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-headquarters",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 準備"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-christmas",
   "metadata": {},
   "source": [
    "### Python version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-sword",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -VV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-remains",
   "metadata": {},
   "source": [
    "### ttslearn のインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-alpha",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "try:\n",
    "    import ttslearn\n",
    "except ImportError:\n",
    "    !pip install ttslearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-click",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ttslearn\n",
    "ttslearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-package",
   "metadata": {},
   "source": [
    "### パッケージのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-bathroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "import IPython\n",
    "from IPython.display import Audio\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-donna",
   "metadata": {},
   "outputs": [],
   "source": [
    "# シードの固定\n",
    "from ttslearn.util import init_seed\n",
    "init_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-softball",
   "metadata": {},
   "source": [
    "### 描画周りの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-outreach",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ttslearn.notebook import get_cmap, init_plot_style, savefig\n",
    "cmap = get_cmap()\n",
    "init_plot_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-share",
   "metadata": {},
   "source": [
    "## 5.3 フルコンテキストラベルとは？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "small-induction",
   "metadata": {},
   "source": [
    "### モノフォンラベル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnmnkwii.io import hts\n",
    "import ttslearn\n",
    "from os.path import basename\n",
    "\n",
    "labels = hts.load(ttslearn.util.example_label_file(mono=True))\n",
    "print(labels[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-bumper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 秒単位に変換\n",
    "# NOTE: 100ナノ秒単位: 100 * 1e-9 = 1e-7\n",
    "for s,e,l in labels[:6]:\n",
    "    print(s*1e-7, e*1e-7, l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-triumph",
   "metadata": {},
   "source": [
    "### フルコンテキストラベル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-process",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = hts.load(ttslearn.util.example_label_file(mono=False))\n",
    "for start_time, end_time, context in labels[:6]:\n",
    "    print(f\"{start_time} {end_time} {context}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-seller",
   "metadata": {},
   "source": [
    "## 5.4 言語特徴量の抽出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-limit",
   "metadata": {},
   "source": [
    "### Open JTalk による言語特徴量の抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-charger",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyopenjtalk\n",
    "\n",
    "pyopenjtalk.g2p(\"今日もいい天気ですね\", kana=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-tamil",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyopenjtalk.g2p(\"今日もいい天気ですね\", kana=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-major",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pyopenjtalk.extract_fullcontext(\"今日\")\n",
    "for label in labels:\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-grant",
   "metadata": {},
   "source": [
    "### HTS 形式の質問ファイル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-light",
   "metadata": {},
   "outputs": [],
   "source": [
    "qst_path = ttslearn.util.example_qst_file()\n",
    "! cat $qst_path | grep QS | head -1\n",
    "! cat $qst_path | grep CQS | head -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-burlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "! head {ttslearn.util.example_qst_file()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-singles",
   "metadata": {},
   "outputs": [],
   "source": [
    "! tail {ttslearn.util.example_qst_file()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-robin",
   "metadata": {},
   "source": [
    "### HTS 形式の質問ファイルの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-mechanics",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnmnkwii.io import hts\n",
    "import ttslearn\n",
    "\n",
    "binary_dict, numeric_dict = hts.load_question_set(ttslearn.util.example_qst_file())\n",
    "\n",
    "# 1番目の質問を確認します\n",
    "name, ex = binary_dict[0]\n",
    "print(\"二値特徴量の数:\", len(binary_dict))\n",
    "print(\"数値特徴量の数:\", len(numeric_dict))\n",
    "print(\"1 つ目の質問:\", name, ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-makeup",
   "metadata": {},
   "source": [
    "### フルコンテキストラベルからの数値表現への変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-pharmaceutical",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnmnkwii.frontend import merlin as fe\n",
    "\n",
    "labels = hts.load(ttslearn.util.example_label_file())\n",
    "feats = fe.linguistic_features(labels, binary_dict, numeric_dict)\n",
    "print(\"言語特徴量（音素単位）のサイズ:\", feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-window",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-graham",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 言語特徴量をフレーム単位に展開"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eligible-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_phoneme = fe.linguistic_features(labels, binary_dict, numeric_dict, add_frame_features=False)\n",
    "feats_frame = fe.linguistic_features(labels, binary_dict, numeric_dict, add_frame_features=True)\n",
    "print(\"言語特徴量（音素単位）のサイズ:\", feats_phoneme.shape)\n",
    "print(\"言語特徴量（フレーム単位）のサイズ:\", feats_frame.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-alberta",
   "metadata": {},
   "source": [
    "### 言語特徴量の可視化 (bonus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-mississippi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可視化用に正規化\n",
    "in_feats = feats_frame / np.maximum(1, np.abs(feats_frame).max(0))\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "mesh = ax.imshow(in_feats.T, aspect=\"auto\", interpolation=\"none\", origin=\"lower\", cmap=cmap)\n",
    "fig.colorbar(mesh, ax=ax)\n",
    "\n",
    "ax.set_xlabel(\"Time [frame]\")\n",
    "ax.set_ylabel(\"Context\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swedish-royalty",
   "metadata": {},
   "source": [
    "## 5.5 音響特徴量の抽出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-validity",
   "metadata": {},
   "source": [
    "### 対数基本周波数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-environment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "import pyworld\n",
    "from nnmnkwii.preprocessing.f0 import interp1d\n",
    "\n",
    "# 基本周波数を対数基本周波数へ変換する関数\n",
    "def f0_to_lf0(f0):\n",
    "    lf0 = f0.copy()\n",
    "    nonzero_indices = np.nonzero(f0)\n",
    "    lf0[nonzero_indices] = np.log(f0[nonzero_indices])\n",
    "    return lf0\n",
    "\n",
    "# 音声ファイルの読み込み\n",
    "sr, x = wavfile.read(ttslearn.util.example_audio_file())\n",
    "x = x.astype(np.float64)\n",
    "\n",
    "# DIO による基本周波数推定\n",
    "f0, timeaxis = pyworld.dio(x, sr)\n",
    "\n",
    "# 基本周波数を対数基本周波数に変換\n",
    "lf0 = f0_to_lf0(f0)\n",
    "\n",
    "# 対数基本周波数に対して線形補間\n",
    "clf0 = interp1d(lf0, kind=\"linear\")\n",
    "\n",
    "# 可視化\n",
    "fig, ax = plt.subplots(figsize=(8, 3))\n",
    "ax.plot(timeaxis, np.exp(lf0), linewidth=2, label=\"F0\")\n",
    "ax.plot(timeaxis, np.exp(clf0), \"--\", linewidth=2, label=\"Continuous F0\")\n",
    "ax.set_xlabel(\"Time [sec]\")\n",
    "ax.set_xticks(np.arange(0.3, 1.4, 0.2))\n",
    "ax.set_xlim(0.28, 1.43)\n",
    "ax.set_ylabel(\"Frequency [Hz]\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# 図5-6\n",
    "savefig(\"fig/dnntts_cf0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-electronics",
   "metadata": {},
   "source": [
    "### 有声/無声フラグ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIO による基本周波数推定\n",
    "f0, timeaxis = pyworld.dio(x, sr)\n",
    "\n",
    "# 有声/無声フラグ の計算\n",
    "vuv = (f0 > 0).astype(np.float32)\n",
    "\n",
    "hop_length = int(sr * 0.005)\n",
    "fig, ax = plt.subplots(2, 1, figsize=(8,4))\n",
    "librosa.display.waveplot(x, sr=sr, x_axis=\"time\", ax=ax[0])\n",
    "ax[1].plot(timeaxis, vuv)\n",
    "ax[1].set_ylim(-0.1, 1.1)\n",
    "\n",
    "ax[0].set_title(\"Waveform\")\n",
    "ax[1].set_title(\"V/UV\")\n",
    "ax[0].set_xlabel(\"Time [sec]\")\n",
    "ax[0].set_ylabel(\"Amplitude\")\n",
    "ax[1].set_xlabel(\"Time [sec]\")\n",
    "ax[1].set_ylabel(\"Binary value\")\n",
    "\n",
    "for a in ax:\n",
    "    a.set_xlim(0.28, 1.43)\n",
    "    a.set_xticks(np.arange(0.3, 1.4, 0.2))\n",
    "plt.tight_layout()\n",
    "\n",
    "# 図5-7\n",
    "savefig(\"fig/dnntts_vuv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-patio",
   "metadata": {},
   "source": [
    "### メルケプストラム"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-apache",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysptk\n",
    "\n",
    "# DIO による基本周波数の推定\n",
    "f0, timeaxis = pyworld.dio(x, sr)\n",
    "\n",
    "# CheapTrick によるスペクトル包絡の推定\n",
    "# 返り値は、パワースペクトルであることに注意 (振幅が 2 乗されている)\n",
    "spectrogram = pyworld.cheaptrick(x, f0, timeaxis, sr)\n",
    "\n",
    "# 線形周波数軸をメル周波数尺度に伸縮し、その後ケプストラムに変換\n",
    "# alpha は周波数軸の伸縮のパラメータを表します\n",
    "alpha = pysptk.util.mcepalpha(sr)\n",
    "# FFT 長は、サンプリング周波数が 48kHz の場合は 2048\n",
    "fftlen = pyworld.get_cheaptrick_fft_size(sr)\n",
    "# メルケプストラムの次元数は、 mgc_order + 1 となります\n",
    "# NOTE: メル一般化ケプストラム (Mel-generalized cepstrum) の頭文字を取り、\n",
    "# 変数名を mgc とします\n",
    "mgc_order = 59\n",
    "mgc = pysptk.sp2mc(spectrogram, mgc_order, alpha)\n",
    "\n",
    "# メルケプストラムから元のスペクトル包絡を復元\n",
    "# スペクトルの次元数は、　fftlen//2 + 1 = 1025\n",
    "spectrogram_reconstructed = pysptk.mc2sp(mgc, alpha, fftlen)\n",
    "\n",
    "# 可視化\n",
    "hop_length = int(sr * 0.005)\n",
    "fig, ax = plt.subplots(3, 1, figsize=(8,8))\n",
    "ax[0].set_title(\"Mel-cepstrum\")\n",
    "ax[1].set_title(\"Reconstructed spectral envelope from Mel-cepstrum\")\n",
    "ax[2].set_title(\"Spectral envelope of natural speech\")\n",
    "\n",
    "mesh = librosa.display.specshow(mgc.T, sr=sr, hop_length=hop_length, x_axis=\"time\", cmap=cmap, ax=ax[0])\n",
    "fig.colorbar(mesh, ax=ax[0])\n",
    "ax[0].set_yticks(np.arange(mgc_order+2)[::10])\n",
    "\n",
    "log_sp_reconstructed = librosa.power_to_db(np.abs(spectrogram_reconstructed), ref=np.max)\n",
    "mesh = librosa.display.specshow(log_sp_reconstructed.T, sr=sr, hop_length=hop_length, x_axis=\"time\", y_axis=\"hz\", cmap=cmap, ax=ax[1])\n",
    "fig.colorbar(mesh, ax=ax[1], format=\"%+2.f dB\")\n",
    "\n",
    "log_sp = librosa.power_to_db(np.abs(spectrogram), ref=np.max)\n",
    "mesh = librosa.display.specshow(log_sp.T, sr=sr, hop_length=hop_length, x_axis=\"time\", y_axis=\"hz\", cmap=cmap, ax=ax[2])\n",
    "fig.colorbar(mesh, ax=ax[2], format=\"%+2.f dB\")\n",
    "\n",
    "ax[1].set_ylim(0, 12000)\n",
    "ax[2].set_ylim(0, 12000)\n",
    "\n",
    "for a in ax:\n",
    "    a.set_xlabel(\"Time [sec]\")\n",
    "    a.set_xlim(0.28, 1.43)\n",
    "    a.set_xticks(np.arange(0.3, 1.4, 0.2))\n",
    "\n",
    "ax[0].set_ylabel(\"Mel channel\")\n",
    "ax[1].set_ylabel(\"Frequency [Hz]\")\n",
    "ax[2].set_ylabel(\"Frequency [Hz]\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# 図5-8\n",
    "savefig(\"fig/dnntts_mcep_reconstructed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-payroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"圧縮率:\", spectrogram.shape[1]/mgc.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "restricted-report",
   "metadata": {},
   "source": [
    "### 帯域非周期性指標"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-anderson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIO による基本周波数の推定\n",
    "f0, timeaxis = pyworld.dio(x, sr)\n",
    "\n",
    "# D4C による非周期性指標の推定\n",
    "aperiodicity= pyworld.d4c(x, f0, timeaxis, sr)\n",
    "\n",
    "# 帯域別の非周期性指標に圧縮\n",
    "bap = pyworld.code_aperiodicity(aperiodicity, sr)\n",
    "\n",
    "# 可視化\n",
    "hop_length = int(sr * 0.005)\n",
    "fig, ax = plt.subplots(2, 1, figsize=(8,6))\n",
    "mesh = librosa.display.specshow(20*np.log10(aperiodicity).T, sr=sr, hop_length=hop_length, x_axis=\"time\", y_axis=\"linear\", cmap=cmap, ax=ax[0])\n",
    "ax[0].set_title(\"Aperiodicity\")\n",
    "fig.colorbar(mesh, ax=ax[0], format=\"%+2.f dB\")\n",
    "\n",
    "mesh = librosa.display.specshow(bap.T, sr=sr, hop_length=hop_length, x_axis=\"time\", cmap=cmap, ax=ax[1])\n",
    "fig.colorbar(mesh, ax=ax[1], format=\"%+2.f dB\")\n",
    "ax[1].set_title(\"Band-aperiodicity\")\n",
    "for a in ax:\n",
    "    a.set_xlabel(\"Time [sec]\")\n",
    "    a.set_ylabel(\"Frequency [Hz]\")\n",
    "    a.set_xlim(0.28, 1.43)\n",
    "    a.set_xticks(np.arange(0.3, 1.4, 0.2))\n",
    "\n",
    "ax[1].set_yticks(np.arange(5+1))\n",
    "ax[1].set_ylabel(\"Frequency band\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# 図5-9\n",
    "savefig(\"fig/dnntts_bap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-replacement",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"圧縮率:\", aperiodicity.shape[1]/bap.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-bulgaria",
   "metadata": {},
   "source": [
    "### 動的特徴量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-realtor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_delta(x, w):\n",
    "    y = np.zeros_like(x)\n",
    "    # 特徴量の次元ごとに動的特徴量を計算\n",
    "    for d in range(x.shape[1]):\n",
    "        y[:, d] = np.correlate(x[:, d], w, mode=\"same\")\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-bargain",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "# スペクトル包絡の推定\n",
    "f0, timeaxis = pyworld.dio(x, sr)\n",
    "spectrogram = pyworld.cheaptrick(x, f0, timeaxis, sr)\n",
    "\n",
    "# パワースペクトルを対数に変換\n",
    "spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "\n",
    "# 動的特徴量の計算\n",
    "delta_window1 = [-0.5, 0.0, 0.5] # 1 次動的特徴量に対する窓\n",
    "delta_window2 = [1.0, -2.0, 1.0] # 2 次動的特徴量に対する窓\n",
    "\n",
    "# 1 次動的特徴量\n",
    "delta = compute_delta(spectrogram, delta_window1)\n",
    "\n",
    "# 2 次動的特徴量\n",
    "deltadelta = compute_delta(spectrogram, delta_window2)\n",
    "\n",
    "# スペクトル包絡に対して動的特徴量を計算して可視化\n",
    "hop_length = int(sr * 0.005)\n",
    "fig, ax = plt.subplots(3, 1, figsize=(8,8))\n",
    "ax[0].set_title(\"Static features\")\n",
    "ax[1].set_title(\"Dynamic features (1st order)\")\n",
    "ax[2].set_title(\"Dynamic features (2nd order)\")\n",
    "mesh = librosa.display.specshow(spectrogram.T, sr=sr, hop_length=hop_length, x_axis=\"time\", y_axis=\"hz\", cmap=cmap, ax=ax[0])\n",
    "fig.colorbar(mesh, ax=ax[0], format=\"%+2.f dB\")\n",
    "mesh = librosa.display.specshow(delta.T, sr=sr, hop_length=hop_length, x_axis=\"time\", y_axis=\"hz\", cmap=cmap, ax=ax[1])\n",
    "fig.colorbar(mesh, ax=ax[1], format=\"%+2.f dB\")\n",
    "mesh = librosa.display.specshow(deltadelta.T, sr=sr, hop_length=hop_length, x_axis=\"time\", y_axis=\"hz\", cmap=cmap, ax=ax[2])\n",
    "fig.colorbar(mesh, ax=ax[2], format=\"%+2.f dB\")\n",
    "\n",
    "for a in ax:\n",
    "    a.set_xlabel(\"Time [sec]\")\n",
    "    a.set_ylabel(\"Frequency [Hz]\")\n",
    "    a.set_ylim(0, 8000)\n",
    "    a.set_xlim(0.28, 1.43)\n",
    "    a.set_xticks(np.arange(0.3, 1.4, 0.2))\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# 図5-10\n",
    "savefig(\"fig/dnntts_dynamic_features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-douglas",
   "metadata": {},
   "source": [
    "### 音響特徴量の結合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-bradford",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnmnkwii.preprocessing import delta_features\n",
    "\n",
    "# WORLD による音声パラメータの推定\n",
    "f0, timeaxis = pyworld.dio(x, sr)\n",
    "spectrogram = pyworld.cheaptrick(x, f0, timeaxis, sr)\n",
    "aperiodicity = pyworld.d4c(x, f0, timeaxis, sr)\n",
    "\n",
    "# スペクトル包絡をメルケプストラムに変換\n",
    "mgc_order = 59\n",
    "alpha = pysptk.util.mcepalpha(sr)\n",
    "mgc = pysptk.sp2mc(spectrogram, mgc_order, alpha)\n",
    "\n",
    "# 有声/無声フラグの計算\n",
    "vuv = (f0 > 0).astype(np.float32)\n",
    "\n",
    "# 連続対数基本周波数系列\n",
    "lf0 = interp1d(f0_to_lf0(f0), kind=\"linear\")\n",
    "\n",
    "# 帯域非周期性指標\n",
    "bap = pyworld.code_aperiodicity(aperiodicity, sr)\n",
    "\n",
    "# 基本周波数と有声/無声フラグを2次元の行列の形にしておく\n",
    "lf0 = lf0[:, np.newaxis] if len(lf0.shape) == 1 else lf0\n",
    "vuv = vuv[:, np.newaxis] if len(vuv.shape) == 1 else vuv\n",
    "\n",
    "# 動的特徴量を計算するための窓\n",
    "windows = [\n",
    "    [1.0],  # 静的特徴量に対する窓\n",
    "    [-0.5, 0.0, 0.5],  # 1次動的特徴量に対する窓\n",
    "    [1.0, -2.0, 1.0],  # 2次動的特徴量に対する窓\n",
    "]\n",
    "\n",
    "# 静的特徴量と動的特徴量を結合した特徴量の計算\n",
    "mgc = delta_features(mgc, windows)\n",
    "lf0 = delta_features(lf0, windows)\n",
    "bap = delta_features(bap, windows)\n",
    "\n",
    "# すべての特徴量を結合した特徴量を作成\n",
    "feats = np.hstack([mgc, lf0, vuv, bap])\n",
    "\n",
    "print(f\"メルケプストラムの次元数: {mgc.shape[1]}\")\n",
    "print(f\"連続対数基本周波数の次元数: {lf0.shape[1]}\")\n",
    "print(f\"有声 / 無声フラグの次元数: {vuv.shape[1]}\")\n",
    "print(f\"帯域非周期性指標の次元数: {bap.shape[1]}\")\n",
    "print(f\"結合された音響特徴量の次元数: {feats.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historical-reset",
   "metadata": {},
   "source": [
    "## 5.6 音声波形の合成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-atlanta",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnmnkwii.paramgen import mlpg\n",
    "from IPython.display import Audio\n",
    "import IPython\n",
    "from ttslearn.dnntts.multistream import get_windows, split_streams\n",
    "from ttslearn.dsp import world_spss_params\n",
    "\n",
    "# 音声ファイルの読み込み\n",
    "sr, x = wavfile.read(ttslearn.util.example_audio_file())\n",
    "x = x.astype(np.float64)\n",
    "\n",
    "# 音響特徴量抽出のパラメータ\n",
    "mgc_order = 59\n",
    "alpha = pysptk.util.mcepalpha(sr)\n",
    "fftlen = pyworld.get_cheaptrick_fft_size(sr)\n",
    "\n",
    "# 音響特徴量の抽出\n",
    "feats = world_spss_params(x, sr, mgc_order)\n",
    "\n",
    "# パラメータ生成に必要な特徴量の分散\n",
    "# 第6章で解説しますが、実際には学習データ全体に対して計算します\n",
    "feats_var = np.var(feats, axis=1)\n",
    "\n",
    "# 結合された特徴量から各特徴量の分離\n",
    "stream_sizes = [(mgc_order+1)*3, 3, 1, pyworld.get_num_aperiodicities(sr)*3]\n",
    "mgc, lf0, vuv, bap = split_streams(feats, stream_sizes)\n",
    "\n",
    "start_ind = np.hstack(([0], np.cumsum(stream_sizes)[:-1]))\n",
    "end_ind = np.cumsum(stream_sizes)\n",
    "\n",
    "# パラメータ生成に必要な、動的特徴量の計算に利用した窓\n",
    "windows = get_windows(num_window=3)\n",
    "\n",
    "# パラメータ生成\n",
    "mgc = mlpg(mgc, feats_var[start_ind[0]:end_ind[0]], windows)\n",
    "lf0 = mlpg(lf0, feats_var[start_ind[1]:end_ind[1]], windows)\n",
    "bap = mlpg(bap, feats_var[start_ind[3]:end_ind[3]], windows)\n",
    "\n",
    "# メルケプストラムからスペクトル包絡への変換\n",
    "spectrogram = pysptk.mc2sp(mgc, alpha, fftlen)\n",
    "\n",
    "# 連続対数基本周波数から基本周波数への変換\n",
    "f0 = lf0.copy()\n",
    "f0[vuv < 0.5] = 0\n",
    "f0[np.nonzero(f0)] = np.exp(f0[np.nonzero(f0)])\n",
    "\n",
    "# 帯域非周期指標から非周期性指標への変換\n",
    "aperiodicity = pyworld.decode_aperiodicity(bap.astype(np.float64), sr, fftlen)\n",
    "\n",
    "# WORLD による音声波形の合成\n",
    "y = pyworld.synthesize(\n",
    "    f0.flatten().astype(np.float64),\n",
    "    spectrogram.astype(np.float64),\n",
    "    aperiodicity.astype(np.float64),\n",
    "    sr\n",
    ")\n",
    "\n",
    "# オーディオプレイヤーの表示\n",
    "IPython.display.display(Audio(x.astype(np.float32), rate=sr))\n",
    "IPython.display.display(Audio(y.astype(np.float32), rate=sr))\n",
    "\n",
    "# 可視化\n",
    "fig, ax = plt.subplots(2, 1, figsize=(8,4), sharey=True)\n",
    "ax[0].set_title(\"Natural speech\")\n",
    "ax[1].set_title(\"Reconstructed speech by acoustic features\")\n",
    "librosa.display.waveplot(x.astype(np.float32), sr, ax=ax[0])\n",
    "librosa.display.waveplot(y.astype(np.float32), sr, ax=ax[1])\n",
    "for a in ax:\n",
    "    a.set_xlabel(\"Time [sec]\")\n",
    "    a.set_ylabel(\"Amplitude\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-richardson",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft =  1024\n",
    "frame_shift = int(sr * 0.005)\n",
    "X = librosa.stft(x.astype(np.float32), n_fft=n_fft, win_length=n_fft, hop_length=frame_shift, window=\"hann\")\n",
    "logX = librosa.amplitude_to_db(np.abs(X), ref=np.max)\n",
    "Y = librosa.stft(y.astype(np.float32), n_fft=n_fft, win_length=n_fft, hop_length=frame_shift, window=\"hann\")\n",
    "log_Y = librosa.amplitude_to_db(np.abs(Y), ref=np.max)\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(8, 6))\n",
    "ax[0].set_title(\"Natural spectrogram\")\n",
    "ax[1].set_title(\"Reconstructed spectrogram from acoustic features\")\n",
    "\n",
    "mesh = librosa.display.specshow(logX, sr=sr, hop_length=hop_length, x_axis=\"time\", y_axis=\"hz\", cmap=cmap, ax=ax[0])\n",
    "fig.colorbar(mesh, ax=ax[0], format=\"%+2.f dB\")\n",
    "mesh = librosa.display.specshow(log_Y, sr=sr, hop_length=hop_length, x_axis=\"time\", y_axis=\"hz\", cmap=cmap, ax=ax[1])\n",
    "fig.colorbar(mesh, ax=ax[1], format=\"%+2.f dB\")\n",
    "\n",
    "for a in ax:\n",
    "    a.set_xlabel(\"Time [sec]\")\n",
    "    a.set_ylabel(\"Frequency [Hz]\")\n",
    "    a.set_ylim(0, 8000)\n",
    "    a.set_xlim(0.28, 1.43)\n",
    "    a.set_xticks(np.arange(0.3, 1.4, 0.2))\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# 図5-13\n",
    "savefig(\"fig/dnntts_waveform_reconstruction\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
